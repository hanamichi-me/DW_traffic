

import pandas as pd
from mlxtend.frequent_patterns import apriori, association_rules
from mlxtend.preprocessing import TransactionEncoder
from mlxtend.frequent_patterns import fpgrowth
import os
from tqdm import tqdm


def load_csv_files(folder_path):
    csv_data = {}
    for filename in os.listdir(folder_path):
        if filename.endswith(".csv"):
            table_name = filename.replace(".csv", "")
            df = pd.read_csv(os.path.join(folder_path, filename))
            csv_data[table_name] = df
    return csv_data


def merge_tables_for_arm(data):
    df = data["fact_person_fatality"].copy()

    # å¤šç»´åº¦ Join
    df = df.merge(data["dim_person"], on="person_id", how="left")
    df = df.merge(data["dim_road"], on="road_id", how="left")
    df = df.merge(data["dim_vehicle"], on="vehicle_id", how="left")
    df = df.merge(data["dim_location"], on="location_id", how="left")
    df = df.merge(data["dim_date"], on="date_id", how="left")
    df = df.merge(data["dim_crash_type"], on="crash_type_id", how="left")
    df = df.merge(data["dim_time"], on="time_of_day_id", how="left")

    # é€‰æ‹©è¦å‚ä¸æŒ–æ˜çš„å­—æ®µ
    selected_fields = [
        "age_group", "gender", "road_type", "speed_limit_group",
        "bus_involvement", "heavy_rigid_truck_involvement", "articulated_truck_involvement",
        "state", "remoteness_area", "day_of_week_name", "day_type",
        "christmas_period", "easter_period", "crash_type", "time_of_day", "road_user"
    ]

    df = df[selected_fields]

    # å°†å¸ƒå°”å‹å­—æ®µè½¬ä¸ºå­—ç¬¦ä¸²ï¼Œé¿å… OneHot ç¼–ç æ—¶è¢«å¿½ç•¥
    bool_cols = ["bus_involvement", "heavy_rigid_truck_involvement", "articulated_truck_involvement",
                 "christmas_period", "easter_period"]
    for col in bool_cols:
        df[col] = df[col].astype(str)

    # åˆ é™¤å«ç¼ºå¤±çš„è®°å½•
    df = df.dropna()

    return df


# def prepare_transactions(df_person, df_date, df_location, df_road, df_vehicle, df_crash_type, df_time):
#     # åˆå¹¶æ‰€æœ‰ç›¸å…³è¡¨
#     df = df_person.merge(df_date, on='date_id', how='left') \
#                   .merge(df_location, on='location_id', how='left') \
#                   .merge(df_road, on='road_id', how='left') \
#                   .merge(df_vehicle, on='vehicle_id', how='left') \
#                   .merge(df_crash_type, on='crash_type_id', how='left') \
#                   .merge(df_time, on='time_of_day_id', how='left')

#     # é€‰æ‹©æœ‰æ„ä¹‰çš„å­—æ®µï¼ˆæ³¨æ„éƒ½æ˜¯åˆ†ç±»å˜é‡ï¼‰
#     selected_cols = [
#         'age_group', 'gender', 'road_user',
#         'state', 'remoteness_area',
#         'road_type', 'speed_limit_group',
#         'bus_involvement', 'heavy_rigid_truck_involvement', 'articulated_truck_involvement',
#         'crash_type', 'time_of_day',
#         'day_of_week_name', 'day_type',
#         'christmas_period', 'easter_period'
#     ]

#     df = df[selected_cols]

#     # æŠŠæ¯åˆ—éƒ½å˜æˆâ€œå­—æ®µ=å€¼â€è¿™ç§æ ¼å¼ï¼Œæ¯”å¦‚ gender=Male
#     df = df.apply(lambda col: col.map(lambda x: f"{col.name}={x}" if pd.notnull(x) else pd.NA))

#     # æ¯ä¸€è¡Œå˜æˆä¸€ä¸ªäº‹åŠ¡ï¼ˆæ¯è¡Œæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼‰
#     transactions = df.apply(lambda row: row.dropna().tolist(), axis=1)

#     # ç”¨ TransactionEncoder åš one-hot ç¼–ç 
#     from mlxtend.preprocessing import TransactionEncoder
#     te = TransactionEncoder()
#     df_encoded = te.fit(transactions).transform(transactions)
#     df_encoded = pd.DataFrame(df_encoded, columns=te.columns_)

#     print(f"âœ… æˆåŠŸæ„é€  {len(df_encoded)} æ¡äº‹åŠ¡ï¼ŒåŒ…å« {len(df_encoded.columns)} ä¸ªå”¯ä¸€é¡¹ã€‚")
#     return df_encoded

tqdm.pandas(desc="ğŸš€ å¤„ç†ä¸­")

def prepare_transactions(df_person, df_date, df_location, df_road, df_vehicle, df_crash_type, df_time):
    # åˆå¹¶æ‰€æœ‰ç›¸å…³è¡¨
    df = df_person.merge(df_date, on='date_id', how='left') \
                  .merge(df_location, on='location_id', how='left') \
                  .merge(df_road, on='road_id', how='left') \
                  .merge(df_vehicle, on='vehicle_id', how='left') \
                  .merge(df_crash_type, on='crash_type_id', how='left') \
                  .merge(df_time, on='time_of_day_id', how='left')

    # é€‰æ‹©æœ‰æ„ä¹‰çš„å­—æ®µï¼ˆæ³¨æ„éƒ½æ˜¯åˆ†ç±»å˜é‡ï¼‰
    selected_cols = [
        'age_group', 'gender', 'road_user',
        'state', 'remoteness_area',
        'road_type', 'speed_limit_group',
        'bus_involvement', 'heavy_rigid_truck_involvement', 'articulated_truck_involvement',
        'crash_type', 'time_of_day',
        'day_of_week_name', 'day_type',
        'christmas_period', 'easter_period'
    ]

    df = df[selected_cols]

    # å°†æ¯åˆ—å€¼è½¬æ¢ä¸ºâ€œå­—æ®µ=å€¼â€å½¢å¼ï¼Œä¾‹å¦‚ "gender=Male"
    df = df.apply(lambda col: col.map(lambda x: f"{col.name}={x}" if pd.notnull(x) else pd.NA))

    # æ¯ä¸€è¡Œå˜æˆä¸€ä¸ªäº‹åŠ¡ï¼ˆList of stringï¼‰ï¼Œä½¿ç”¨ tqdm å±•ç¤ºå¤„ç†è¿›åº¦
    transactions = df.progress_apply(lambda row: row.dropna().tolist(), axis=1)

    # One-hot ç¼–ç è½¬æ¢ä¸ºå¸ƒå°”ç‰¹å¾çŸ©é˜µ
    te = TransactionEncoder()
    df_encoded = te.fit(transactions).transform(transactions)
    df_encoded = pd.DataFrame(df_encoded, columns=te.columns_)

    print(f"\nâœ… æˆåŠŸæ„é€  {len(df_encoded)} æ¡äº‹åŠ¡ï¼ŒåŒ…å« {len(df_encoded.columns)} ä¸ªå”¯ä¸€é¡¹ã€‚")
    return df_encoded




def mine_association_rules(df_trans, target_rhs="road_user=", min_support=0.05, min_confidence=0.60, min_lift=1.0, top_k=10):
    freq_items = apriori(df_trans, min_support=min_support, use_colnames=True)
    rules = association_rules(freq_items, metric="lift", min_threshold=min_lift)

    # ä»…ä¿ç•™å³ä¾§åªåŒ…å«ä¸€ä¸ª road_user=xxx çš„è§„åˆ™
    rules = rules[
        rules['consequents'].apply(lambda x: len(x) == 1 and list(x)[0].startswith(target_rhs))
    ]

    # confidence è¾ƒé«˜ï¼ŒæŒ‰ lift å’Œ confidence æ’åº
    rules = rules[rules['confidence'] >= min_confidence]
    # rules = rules.sort_values(by=["lift", "confidence"], ascending=False).head(top_k)
    rules = rules.sort_values(by=["lift", "confidence"], ascending=False).head(top_k)


    return rules



# def mine_association_rules(df_trans, target_rhs="road_user=", min_support=0.06, min_confidence=0.60, min_lift=2.0, top_k=10):
#     print("ğŸ” æ­£åœ¨ç”Ÿæˆé¢‘ç¹é¡¹é›† ...")
#     freq_items = fpgrowth(df_trans, min_support=min_support, use_colnames=True)

#     print("ğŸ§  æ­£åœ¨æŒ–æ˜å…³è”è§„åˆ™ ...")
#     rules = association_rules(freq_items, metric="lift", min_threshold=min_lift)

#     rules = rules[
#         rules['consequents'].apply(lambda x: len(x) == 1 and list(x)[0].startswith(target_rhs))
#     ]
#     rules = rules[rules['confidence'] >= min_confidence]
#     rules = rules.sort_values(by=[ "lift", "confidence"], ascending=False).head(top_k)

#     return rules




def main():
    data = load_csv_files("DB_files_export")

    df_trans = prepare_transactions(
        df_person=data["fact_person_fatality"].merge(data["dim_person"], on="person_id"),
        df_date=data["dim_date"],
        df_location=data["dim_location"],
        df_road=data["dim_road"],
        df_vehicle=data["dim_vehicle"],
        df_crash_type=data["dim_crash_type"],
        df_time=data["dim_time"]
    )

    rules = mine_association_rules(df_trans, target_rhs="road_user=")

    print("ğŸ“‹ Top Rules with 'road_user' on the RHS:")
    print(rules[["antecedents", "consequents", "support", "confidence", "lift"]])

    # âœ… å¯¼å‡ºåˆ° output_rules æ–‡ä»¶å¤¹
    output_dir = "output_rules"
    os.makedirs(output_dir, exist_ok=True)
    output_path = os.path.join(output_dir, "road_user_rules.csv")
    rules.to_csv(output_path, index=False)
    print(f"âœ… å·²ä¿å­˜å…³è”è§„åˆ™åˆ°æ–‡ä»¶: {output_path}")



if __name__ == "__main__":
    main()
